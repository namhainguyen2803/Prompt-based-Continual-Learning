Index: learners/prompt.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import print_function\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport models\nfrom models.ContrastiveLoss import ContrastivePrototypicalLoss\nfrom utils.metric import AverageMeter, Timer\nfrom utils.schedulers import CosineSchedule\nfrom .default import NormalNN, accumulate_acc\nfrom models.ClusterAlgorithm import KMeans\nfrom models.EmbeddingProjection import EmbeddingMLP, MLP\n\n\nclass Prompt(NormalNN):\n\n    def __init__(self, learner_config):\n        self.prompt_param = learner_config['prompt_param']\n        self.prompt_type = learner_config['prompt_type']\n\n        super(Prompt, self).__init__(learner_config)\n\n    def update_model(self, inputs, targets):\n\n        logit, _, prompt_loss = self.model(x=inputs, get_logit=True, train=True,\n                                           use_prompt=True, task_id=None, prompt_type=self.prompt_type)\n        logit = logit[:, :self.valid_out_dim]\n\n        # ce with heuristic\n        # logit[:, :self.last_valid_out_dim] = -float('inf')\n        dw_cls = self.dw_k[-1 * torch.ones(targets.size()).long()]\n        total_loss = self.criterion(logit[:, self.last_valid_out_dim:], (targets - self.last_valid_out_dim).long(),\n                                    dw_cls)\n\n        # ce loss\n        total_loss = total_loss + prompt_loss.sum()\n\n        # step\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        self.optimizer.step()\n\n        return total_loss.detach(), logit\n\n    def _set_learnable_parameter(self):\n        if len(self.config['gpuid']) > 1:\n            params_to_opt = list(self.model.module.prompt.parameters()) + list(self.model.module.last.parameters())\n        else:\n            params_to_opt = list(self.model.prompt.parameters()) + list(self.model.last.parameters())\n        return params_to_opt\n\n    def init_optimizer(self):\n        params_to_opt = self._set_learnable_parameter()\n        print('*****************************************')\n        optimizer_arg = {'params': params_to_opt,\n                         'lr': self.config['lr'],\n                         'weight_decay': self.config['weight_decay']}\n        if self.config['optimizer'] in ['SGD', 'RMSprop']:\n            optimizer_arg['momentum'] = self.config['momentum']\n        elif self.config['optimizer'] in ['Rprop']:\n            optimizer_arg.pop('weight_decay')\n        elif self.config['optimizer'] == 'amsgrad':\n            optimizer_arg['amsgrad'] = True\n            self.config['optimizer'] = 'Adam'\n        elif self.config['optimizer'] == 'Adam':\n            optimizer_arg['betas'] = (self.config['momentum'], 0.999)\n        elif self.config[\"optimizer\"] == \"AdamW\":\n            optimizer_arg[\"betas\"] = (0.9, 0.999)\n\n        # create optimizers\n        self.optimizer = torch.optim.__dict__[self.config['optimizer']](**optimizer_arg)\n        # create schedules\n        if self.schedule_type == 'cosine':\n            self.scheduler = CosineSchedule(self.optimizer, K=self.schedule[-1])\n        elif self.schedule_type == 'decay':\n            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.schedule, gamma=0.1)\n\n    def create_model(self):\n        pass\n\n    def cuda(self):\n        torch.cuda.set_device(self.config['gpuid'][0])\n        self.model = self.model.cuda()\n        self.criterion_fn = self.criterion_fn.cuda()\n\n        # Multi-GPU\n        if len(self.config['gpuid']) > 1:\n            self.model = torch.nn.DataParallel(self.model, device_ids=self.config['gpuid'],\n                                               output_device=self.config['gpuid'][0])\n        return self\n\n\nclass CODAPrompt(Prompt):\n\n    def __init__(self, learner_config):\n        super(CODAPrompt, self).__init__(learner_config)\n\n    def create_model(self):\n        cfg = self.config\n        model = models.__dict__[cfg['model_type']].__dict__[cfg['model_name']](out_dim=self.out_dim, prompt_flag='coda',\n                                                                               prompt_param=self.prompt_param)\n        return model\n\n\nclass DualPrompt(Prompt):\n\n    def __init__(self, learner_config):\n        super(DualPrompt, self).__init__(learner_config)\n\n    def create_model(self):\n        cfg = self.config\n        model = models.__dict__[cfg['model_type']].__dict__[cfg['model_name']](out_dim=self.out_dim, prompt_flag='dual',\n                                                                               prompt_param=self.prompt_param)\n        return model\n\n\nclass L2P(Prompt):\n\n    def __init__(self, learner_config):\n        super(L2P, self).__init__(learner_config)\n\n    def create_model(self):\n        cfg = self.config\n        model = models.__dict__[cfg['model_type']].__dict__[cfg['model_name']](out_dim=self.out_dim, prompt_flag='l2p',\n                                                                               prompt_param=self.prompt_param)\n        return model\n\n\nclass ContrastivePrototypicalPrompt(Prompt):\n\n    def __init__(self, learner_config):\n        super(ContrastivePrototypicalPrompt, self).__init__(learner_config)\n\n        self.key_prototype = dict()\n        self.value_prototype = dict()\n        self.avg_variance = dict()\n        self.MLP_neck = None\n        self._num_anchor_value_prototype_per_class = 5\n        self._num_anchor_key_prototype_per_class = 5\n        self._create_mapping_from_class_to_task()\n\n    def create_model(self):\n        cfg = self.config\n        model = models.__dict__[cfg['model_type']].__dict__[cfg['model_name']](out_dim=self.out_dim, prompt_flag='cpp',\n                                                                               prompt_param=self.prompt_param)\n        return model\n\n    def _create_mapping_from_class_to_task(self):\n        self.mapping_class_to_task = dict()\n        for task_id, class_range in enumerate(self.tasks):\n            for class_id in class_range:\n                self.mapping_class_to_task[class_id] = task_id\n\n    def _create_criterion_fn(self):\n        self.criterion_fn = ContrastivePrototypicalLoss(temperature=0.6, reduction=\"mean\")\n\n    def _learnable_params(self):\n        if len(self.config['gpuid']) > 1:\n            params_to_opt = list(self.model.module.prompt.parameters()) + list(self.MLP_neck.module.parameters())\n        else:\n            params_to_opt = list(self.model.prompt.parameters()) + list(self.MLP_neck.parameters())\n        return params_to_opt\n\n    def _update_prototype_set(self, prototype_set, train_loader, use_prompt=False):\n        \"\"\"\n        Function to update prototype of previous class.\n        \"\"\"\n        with torch.no_grad():\n            list_last_feature = list()\n            list_output = list()\n            for i, (x, y, task) in enumerate(train_loader):\n                self.model.eval()\n                if self.gpu:\n                    x = x.cuda()\n                    y = y.cuda()\n\n                if use_prompt:\n                    last_feature, _ = self.model(x, get_logit=False, train=False, use_prompt=True,\n                                                 task_id=task, prompt_type=self.prompt_type)\n                else:\n                    last_feature, _ = self.model(x, get_logit=False, train=False, use_prompt=False,\n                                                 task_id=task, prompt_type=self.prompt_type)\n\n                list_last_feature.append(last_feature)\n                list_output.append(y)\n\n            last_features = torch.cat(list_last_feature, dim=0)\n            outputs = torch.cat(list_output, dim=0)\n            uni_output = sorted(torch.unique(outputs).tolist())\n            for class_id in uni_output:\n                if use_prompt:\n                    cluster_algorithm = KMeans(num_classes=self._num_anchor_value_prototype_per_class)\n                else:\n                    cluster_algorithm = KMeans(num_classes=self._num_anchor_key_prototype_per_class)\n                feature_set_for_class_id = last_features[outputs == class_id]\n                assert feature_set_for_class_id.ndim == 2, \"feature_set_for_class_id.ndim != 2.\"\n                cluster_algorithm.fit(feature_set_for_class_id)\n                prototype = cluster_algorithm.get_centroids()\n                prototype_set[class_id] = prototype  # (_num_anchor_per_class, emb_d)\n                check_tensor_nan(prototype, \"prototype\")\n                check_tensor_nan(feature_set_for_class_id, \"feature_set_for_class_id\")\n                if use_prompt:\n                    # row_variances = torch.var(feature_set_for_class_id, dim=1)\n                    # self.avg_variance[class_id] = torch.mean(row_variances)\n                    # print(self.avg_variance[class_id])\n                    self.avg_variance[class_id] = torch.tensor(1.0)\n            return prototype_set\n\n    def _update_key_prototype(self, train_loader):\n        self.key_prototype = self._update_prototype_set(prototype_set=self.key_prototype, train_loader=train_loader,\n                                                        use_prompt=False)\n\n    def _update_value_prototype(self, train_loader):\n        self.value_prototype = self._update_prototype_set(prototype_set=self.value_prototype, train_loader=train_loader,\n                                                          use_prompt=True)\n\n    def learn_batch(self, train_loader, train_dataset, model_save_dir, val_loader=None, need_loss=True, need_acc=False):\n        print(\"##### Attempt to update key prototype set. #####\")\n        self._update_key_prototype(train_loader)\n        print(\"##### Finish updating key prototype set. #####\")\n        # re-initialize MLP neck\n        self._reset_MLP_neck()\n        print(\"Reset MLP neck.\")\n        # learn prompt\n        print(f\"##### Attempt to learn batch in task id: {self.model.task_id}. #####\")\n        self._learn_batch(train_loader, train_dataset, model_save_dir, val_loader=val_loader, need_loss=need_loss)\n        print(f\"##### Finish learning batch in task id: {self.model.task_id}. #####\")\n        print(\"##### Attempt to update value prototype set. #####\")\n        self._update_value_prototype(train_loader)\n        print(\"##### Finish updating value prototype set. #####\")\n\n    def _learn_batch(self, train_loader, train_dataset, model_save_dir, val_loader=None, need_loss=True):\n        # try to load model\n        need_train = True\n        if not self.overwrite:\n            try:\n                self.load_model(model_save_dir)\n                need_train = False\n            except:\n                print(\"Cannot load model\")\n        # trains\n        if self.reset_optimizer:  # Reset optimizer before learning each task\n            self.log('Optimizer is reset!')\n            self.init_optimizer()\n        if need_train:\n            losses = AverageMeter()\n            batch_time = AverageMeter()\n            batch_timer = Timer()\n            all_previous_value_prototype = None\n            avg_var = None\n            if not self.first_task:\n                # retrieve all perturbed prototype set in a single tensor\n                all_previous_value_prototype = list()\n                for class_id, value_prototype_set in self.value_prototype.items():\n                    if value_prototype_set.ndim == 1:\n                        value_prototype_set = value_prototype_set.unsqueeze(0)\n                    assert value_prototype_set.ndim == 2, \"all_previous_value_prototype.ndim != 2.\"\n                    all_previous_value_prototype.append(value_prototype_set)\n                all_previous_value_prototype = torch.cat(all_previous_value_prototype, dim=0)\n                assert all_previous_value_prototype.ndim == 2, \"all_previous_value_prototype.ndim != 2.\"\n                print(f\"Check value_prototype, having shape: {all_previous_value_prototype.shape}, \"\n                      f\"requires grad: {all_previous_value_prototype.requires_grad}\")\n                avg_var = list()\n                for class_id, avg_var_for_each_class in self.avg_variance.items():\n                    if class_id < self.last_valid_out_dim:\n                        avg_var.append(avg_var_for_each_class)  # avg_var_for_each_class is a number\n                avg_var = torch.tensor(avg_var)\n                assert avg_var.shape[0] * self._num_anchor_value_prototype_per_class == \\\n                       all_previous_value_prototype.shape[0]\n                # stretch avg_var to be the same size as prototype.shape[0]\n                avg_var = avg_var.repeat(self._num_anchor_value_prototype_per_class).unsqueeze(-1).cuda()\n\n            for epoch in range(self.config['schedule'][-1]):\n                self.epoch = epoch\n                if epoch > 0:\n                    self.scheduler.step()\n                for param_group in self.optimizer.param_groups:\n                    self.log('LR:', param_group['lr'])\n                batch_timer.tic()\n                for i, (x, y, task) in enumerate(train_loader):\n                    # verify in train mode\n                    self.model.train()\n                    # send data to gpu\n                    if self.gpu:\n                        x = x.cuda()\n                        y = y.cuda()\n                    # model update\n\n                    loss = self.update_model(inputs=x, targets=y, prompt_type=self.prompt_type,\n                                             all_previous_value_prototype=all_previous_value_prototype, avg_var=avg_var)\n                    # print(loss)\n                    # measure elapsed time\n                    batch_time.update(batch_timer.toc())\n                    batch_timer.tic()\n                    # measure accuracy and record loss\n                    y = y.detach()\n                    if need_loss:\n                        losses.update(loss, y.size(0))\n                    batch_timer.tic()\n                # eval update\n                self.log(\n                    'Epoch:{epoch:.0f}/{total:.0f}'.format(epoch=self.epoch + 1, total=self.config['schedule'][-1]))\n                self.log(' * Loss {loss.avg:.3f} |'.format(loss=losses))\n                losses = AverageMeter()\n\n        self.model.eval()\n        self.last_valid_out_dim = self.valid_out_dim\n        self.first_task = False\n        # Extend memory\n        self.task_count += 1\n        if self.memory_size > 0:\n            train_dataset.update_coreset(self.memory_size, np.arange(self.last_valid_out_dim))\n        try:\n            return batch_time.avg\n        except:\n            return None\n\n    def _perturb_value_prototype(self, prototype, avg_var):\n        with torch.no_grad():\n            vect_dim = prototype.shape[1]\n            num_instances = prototype.shape[0]\n            mean = torch.zeros(vect_dim)\n            covariance = torch.eye(vect_dim)\n            gaussian_noise = torch.distributions.MultivariateNormal(mean, covariance).sample([num_instances]).cuda()\n            return prototype + avg_var * gaussian_noise\n\n    def update_model(self, inputs, targets, prompt_type=\"prefix\", all_previous_value_prototype=None, avg_var=None):\n        # logits\n        if not self.first_task:\n            if avg_var is not None and all_previous_value_prototype is not None:\n                all_previous_value_prototype = self._perturb_value_prototype(all_previous_value_prototype, avg_var)\n            all_previous_value_prototype = nn.functional.normalize(all_previous_value_prototype, dim=1)\n            check_tensor_nan(all_previous_value_prototype, \"all_previous_value_prototype\")\n\n        last_feature, _ = self.model(inputs, get_logit=False, train=True,\n                                     use_prompt=True, task_id=None, prompt_type=prompt_type)\n\n        check_tensor_nan(last_feature, \"last_feature\")\n        z_feature = self.MLP_neck(last_feature)\n        n_z_feature = nn.functional.normalize(z_feature, dim=1)\n        total_loss = self.criterion_fn(z_feature=n_z_feature, label=targets,\n                                       previous_prototype=all_previous_value_prototype)\n        # step\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        self.optimizer.step()\n        return total_loss.detach()\n\n    def validation(self, dataloader, model=None, task_in=None, task_metric='acc', verbal=True):\n        with torch.no_grad():\n            if model is None:\n                model = self.model\n            # This function doesn't distinguish tasks.\n            batch_timer = Timer()\n            acc = AverageMeter()\n            batch_timer.tic()\n            orig_mode = model.training\n            model.eval()\n            U = list()\n            U_hat = list()\n            for class_id in range(self.valid_out_dim):\n                key = self.key_prototype[class_id].unsqueeze(0)\n                value = self.value_prototype[class_id].unsqueeze(0)\n                U.append(key)\n                U_hat.append(value)\n            U = torch.cat(U, dim=0)  # (num_classes, num_anchors, emb_d)\n            U_hat = torch.cat(U_hat, dim=0)\n            assert U.ndim == 3, \"Wrong in shape U.\"\n            assert U_hat.ndim == 3, \"Wrong in shape U_hat.\"\n            print(f\"Shape of U: {U.shape}, Shape of U_hat: {U_hat.shape}\")\n            check_tensor_nan(U, \"U\")\n            check_tensor_nan(U_hat, \"U_hat\")\n            total_correct = 0\n            total_element = 0\n\n            for i, (input, target, task) in enumerate(dataloader):\n                if self.gpu:\n                    with torch.no_grad():\n                        input = input.cuda()\n                        target = target.cuda()\n                if task_in is None:\n                    acc, correct_task, num_element = self._evaluate(model=model, input=input,\n                                                                    target=target, task=task,\n                                                                    acc=acc, task_in=None, U=U, U_hat=U_hat)\n                else:\n                    mask = target >= task_in[0]\n                    mask_ind = mask.nonzero().view(-1)\n                    input, target = input[mask_ind], target[mask_ind]\n                    mask = target < task_in[-1]\n                    mask_ind = mask.nonzero().view(-1)\n                    input, target = input[mask_ind], target[mask_ind]\n                    acc, correct_task, num_element = self._evaluate(model=model, input=input,\n                                                                    target=target, task=task, acc=acc,\n                                                                    task_in=task_in, U=U, U_hat=U_hat)\n                total_correct += correct_task\n                total_element += num_element\n        model.train(orig_mode)\n        if verbal:\n            ground_truth_task = torch.unique(task).cuda()\n            self.log(f\"In task {ground_truth_task}, \"\n                     f\"number of correct task: {total_correct} in {total_element} elements\")\n            self.log(' * Val Acc {acc.avg:.3f}, Total time {time:.2f}'\n                     .format(acc=acc, time=batch_timer.toc()))\n        return acc.avg\n\n    def _evaluate(self, model, input, target, task, acc, task_in=None, U=None, U_hat=None):\n        with torch.no_grad():\n            top_k = model.prompt.top_k\n            # retrieve prototype set in a tensor with ascending order wrt class_id\n            x_query = model.retrieve_query_vector(input)\n            B, C = x_query.shape\n            # cosine similarity to match keys/queries\n            n_U = nn.functional.normalize(U, dim=2)  # (num_classes, num_anchors, emb_d)\n            q = nn.functional.normalize(x_query, dim=1).detach()  # (B, emb_d)\n            cos_sim = torch.einsum('kj,bij->kbi', q, n_U)  # (B, num_classes, num_anchors)\n            flatten_cos_sim = cos_sim.reshape(B, -1)  # (B, num_classes * num_anchors)\n            prototype_id_ranking = torch.topk(flatten_cos_sim, top_k, dim=1)\n            ranking = prototype_id_ranking.indices  # shape == (B, self.top_k)\n            possible_task_id = torch.zeros_like(ranking).cuda()\n\n            for class_id in range(self.valid_out_dim):\n                # [0, 5]\n                class_range = (class_id * self._num_anchor_key_prototype_per_class,\n                               (class_id + 1) * self._num_anchor_key_prototype_per_class)\n                for c in range(class_range[0], class_range[1]):\n                    possible_task_id[ranking == c] = self.mapping_class_to_task[class_id]\n\n            diff = possible_task_id - task.unsqueeze(1).cuda()\n            same = torch.zeros_like(diff).cuda()\n            same[diff == 0] = 1\n            same[diff != 0] = 0\n            same = torch.sum(same, dim=1)\n            same[same > 1] = 1\n\n            num_element_correct_task = torch.sum(same)\n            flatten_possible_task_id = possible_task_id.reshape(-1, 1)  # flatten, shape == (B * self.top_k, 1)\n            flatten_possible_task_id = flatten_possible_task_id.squeeze(-1)\n\n            inp = input.unsqueeze(0)\n            input_repeat = inp.repeat(top_k, 1, 1, 1, 1)\n            input_repeat = input_repeat.permute(1, 0, 2, 3, 4)\n            input_repeat = input_repeat.reshape(-1, input_repeat.shape[2], input_repeat.shape[3], input_repeat.shape[4])\n\n            # print(f\"shape of input_repeat: {input_repeat.shape}\")\n            last_feature, _ = self.model(input_repeat, get_logit=False, train=False,\n                                         use_prompt=True, task_id=flatten_possible_task_id,\n                                         prompt_type=self.prompt_type)\n            # last_feature.shape == (B * self.top_k, emb_d)\n            # print(f\"shape of last_feature: {last_feature.shape}\")\n            assert last_feature.shape == (B * top_k, self.model.prompt.emb_d), \\\n                \"last_feature.shape != (B * top_k, self.model.prompt.emb_d).\"\n            fine_grained_query = last_feature.reshape(B, top_k, self.model.prompt.emb_d)\n\n            n_U_hat = nn.functional.normalize(U_hat, dim=-1)  # (num_classes, num_anchors, emb_d)\n            n_fine_grained_query = nn.functional.normalize(fine_grained_query, dim=-1)  # (B, top_k, emb_d)\n            assert n_fine_grained_query.shape == (B, top_k, self.model.prompt.emb_d), \"Wrong in _evaluate method (2).\"\n\n            # likelihood_among_top_k_classes.shape == (B, num_classes, top_k, num_anchors)\n            likelihood_among_top_k_classes = torch.einsum('bij,tkj->btik', n_fine_grained_query, n_U_hat)\n            likelihood_among_top_k_classes = likelihood_among_top_k_classes.reshape(B, self.valid_out_dim, -1)\n            max_likelihood_among_k_classes = torch.max(likelihood_among_top_k_classes, dim=-1).values\n            assert max_likelihood_among_k_classes.shape == (B, self.valid_out_dim), \"Wrong in _evaluate method (3).\"\n\n            if task_in is None:\n                output = max_likelihood_among_k_classes\n                acc = accumulate_acc(output, target, task, acc, topk=(self.top_k,))\n            else:\n                output = max_likelihood_among_k_classes[:, task_in]\n                acc = accumulate_acc(output, target - task_in[0], task, acc, topk=(self.top_k,))\n            return acc, num_element_correct_task, B\n\n    def _reset_MLP_neck(self):\n        if self.MLP_neck is not None:\n            del self.MLP_neck\n        self.MLP_neck = EmbeddingMLP().cuda()\n\n\nclass ProgressivePrompt(Prompt):\n\n    def __init__(self, learner_config):\n        super(ProgressivePrompt, self).__init__(learner_config)\n        self.prompt_MLP_params = None\n        self.classifier_dict = dict()\n        self.dict_last_valid_out_dim = dict()\n\n    def create_model(self):\n        cfg = self.config\n        model = models.__dict__[cfg['model_type']].__dict__[cfg['model_name']](out_dim=self.out_dim,\n                                                                               prompt_flag='concat',\n                                                                               prompt_param=self.prompt_param)\n        return model\n\n    def _set_learnable_parameter(self):\n\n        if len(self.config['gpuid']) > 1:\n            params_to_opt = list(self.model.module.prompt.parameters()) + \\\n                            list(self.classifier_dict[self.model.task_id].parameters())\n        else:\n            params_to_opt = list(self.model.prompt.parameters()) + \\\n                            list(self.classifier_dict[self.model.task_id].parameters())\n        return params_to_opt\n\n    def learn_batch(self, train_loader, train_dataset, model_save_dir, val_loader=None, normalize_target=True):\n        self.dict_last_valid_out_dim[self.model.task_id] = self.last_valid_out_dim\n        self.create_classifier(self.model.task_id)\n        if not self.first_task:\n            self.model.prompt.concatenate_prompt(self.model.task_id)\n        super().learn_batch(train_loader=train_loader, train_dataset=train_dataset,\n                            model_save_dir=model_save_dir, val_loader=val_loader, normalize_target=normalize_target)\n\n    def create_classifier(self, task_id):\n        feature_dim = self.model.prompt.emb_d\n        num_classes = len(self.tasks[task_id])\n        model = nn.Linear(in_features=feature_dim, out_features=num_classes).cuda()\n        self.classifier_dict[task_id] = model\n\n    def update_model(self, inputs, targets):\n\n        feature, _ = self.model(x=inputs, get_logit=False, train=True,\n                                use_prompt=True, task_id=None, prompt_type=self.prompt_type)\n\n        logit = self.classifier_dict[self.model.task_id](feature)\n\n        # ce with heuristic\n        # logit[:, :self.last_valid_out_dim] = -float('inf')\n        dw_cls = self.dw_k[-1 * torch.ones(targets.size()).long()]\n        total_loss = self.criterion(logit, targets.long(), dw_cls)\n\n        # step\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        self.model.prompt.freeze_previous_prompt(self.model.task_id)\n        self.optimizer.step()\n\n        return total_loss.detach(), logit\n\n    def _evaluate(self, model, input, target, task, acc, task_in=None):\n        with torch.no_grad():\n            task = torch.unique(task)[0].item()\n            last_valid = self.dict_last_valid_out_dim[task]\n            if task_in is None:\n                feature, _ = model(input, get_logit=False, train=False, use_prompt=True,\n                                    task_id=task, prompt_type=self.prompt_type)\n                output = self.classifier_dict[task](feature)\n                acc = accumulate_acc(output, target-last_valid, task, acc, topk=(self.top_k,))\n            else:\n                feature, _ = model(input, get_logit=True, train=False, use_prompt=True,\n                                    task_id=task, prompt_type=self.prompt_type)\n                output = self.classifier_dict[task](feature)\n                acc = accumulate_acc(output, target - task_in[0], task, acc, topk=(self.top_k,))\n            return acc\n\n\ndef check_tensor_nan(tensor, tensor_name=\"a\"):\n    has_nan = torch.isnan(tensor).any().item()\n    if has_nan:\n        raise f\"Tensor {tensor_name} is nan.\"\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/learners/prompt.py b/learners/prompt.py
--- a/learners/prompt.py	(revision ef3207f084055e74046cf629bac1d2ccbd7a0a28)
+++ b/learners/prompt.py	(date 1695874951538)
@@ -550,6 +550,7 @@
                 acc = accumulate_acc(output, target - task_in[0], task, acc, topk=(self.top_k,))
             return acc
 
+# class
 
 def check_tensor_nan(tensor, tensor_name="a"):
     has_nan = torch.isnan(tensor).any().item()
